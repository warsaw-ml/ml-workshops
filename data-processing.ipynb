{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pycocotools.coco import COCO\n",
    "from shutil import copyfile\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your downloaded COCO dataset\n",
    "annotations_file = 'data/annotations/instances_val2014.json'\n",
    "images_dir = 'data/val2014'\n",
    "output_dir = 'data/person_val2014/'\n",
    "output_annotations_file = 'data/annotations/person_instances_val2014.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=2.69s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Load COCO annotations\n",
    "coco = COCO(annotations_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all category IDs and their names\n",
    "categories = coco.loadCats(coco.getCatIds())\n",
    "category_names = [cat['name'] for cat in categories]\n",
    "category_id_map = {cat['name']: cat['id'] for cat in categories}\n",
    "\n",
    "# Get the category ID for \"person\"\n",
    "person_category_id = category_id_map['person']\n",
    "\n",
    "# Get all image IDs that contain a person\n",
    "person_image_ids = coco.getImgIds(catIds=[person_category_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted and downsampled to 7139 person images and annotations.\n"
     ]
    }
   ],
   "source": [
    "# Define the undersampling ratio or the number of images to keep\n",
    "downsample_ratio = 0.33  # For example, keep 10% of the images\n",
    "num_images_to_keep = int(len(person_image_ids) * downsample_ratio)\n",
    "\n",
    "# Randomly select a subset of the image IDs\n",
    "selected_image_ids = random.sample(person_image_ids, num_images_to_keep)\n",
    "\n",
    "# Get all person annotations\n",
    "person_annotations = coco.loadAnns(coco.getAnnIds(imgIds=selected_image_ids, catIds=[person_category_id]))\n",
    "\n",
    "# Create output directory for person images\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Copy selected person images to the output directory\n",
    "for img_id in selected_image_ids:\n",
    "    img_info = coco.loadImgs(img_id)[0]\n",
    "    img_filename = img_info['file_name']\n",
    "    src_path = os.path.join(images_dir, img_filename)\n",
    "    dst_path = os.path.join(output_dir, img_filename)\n",
    "    copyfile(src_path, dst_path)\n",
    "\n",
    "# Save person annotations to a new JSON file\n",
    "person_data = {\n",
    "    'images': [coco.loadImgs(img_id)[0] for img_id in selected_image_ids],\n",
    "    'annotations': person_annotations,\n",
    "    'categories': [cat for cat in categories if cat['id'] == person_category_id]\n",
    "}\n",
    "\n",
    "with open(output_annotations_file, 'w') as f:\n",
    "    json.dump(person_data, f)\n",
    "\n",
    "print(f'Extracted and downsampled to {num_images_to_keep} person images and annotations.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your two COCO datasets\n",
    "dataset1_annotations_file = 'dataset1/annotations/instances_train2017.json'\n",
    "dataset1_images_dir = 'dataset1/train2017/'\n",
    "dataset2_annotations_file = 'dataset2/annotations/instances_train2017.json'\n",
    "dataset2_images_dir = 'dataset2/train2017/'\n",
    "\n",
    "# Output paths\n",
    "output_dir = 'combined_dataset/train2017/'\n",
    "output_annotations_file = 'combined_dataset/annotations/instances_train2017.json'\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Load the annotations for both datasets\n",
    "with open(dataset1_annotations_file, 'r') as f:\n",
    "    dataset1 = json.load(f)\n",
    "with open(dataset2_annotations_file, 'r') as f:\n",
    "    dataset2 = json.load(f)\n",
    "\n",
    "# Ensure category IDs are unique across both datasets\n",
    "# Assuming each dataset has only one class, we can simply append them and adjust IDs if needed\n",
    "dataset2_category_id_offset = max(cat['id'] for cat in dataset1['categories']) + 1\n",
    "for category in dataset2['categories']:\n",
    "    category['id'] += dataset2_category_id_offset\n",
    "\n",
    "# Merge categories\n",
    "merged_categories = dataset1['categories'] + dataset2['categories']\n",
    "\n",
    "# Ensure image IDs are unique across both datasets\n",
    "dataset2_image_id_offset = max(img['id'] for img in dataset1['images']) + 1\n",
    "for image in dataset2['images']:\n",
    "    image['id'] += dataset2_image_id_offset\n",
    "\n",
    "# Ensure annotation IDs are unique and update image IDs in annotations\n",
    "dataset2_annotation_id_offset = max(ann['id'] for ann in dataset1['annotations']) + 1\n",
    "for annotation in dataset2['annotations']:\n",
    "    annotation['id'] += dataset2_annotation_id_offset\n",
    "    annotation['image_id'] += dataset2_image_id_offset\n",
    "\n",
    "# Merge images and annotations\n",
    "merged_images = dataset1['images'] + dataset2['images']\n",
    "merged_annotations = dataset1['annotations'] + dataset2['annotations']\n",
    "\n",
    "# Copy images to the output directory\n",
    "for image in merged_images:\n",
    "    src_path = os.path.join(dataset1_images_dir if image['id'] < dataset2_image_id_offset else dataset2_images_dir, image['file_name'])\n",
    "    dst_path = os.path.join(output_dir, image['file_name'])\n",
    "    if not os.path.exists(dst_path):\n",
    "        copyfile(src_path, dst_path)\n",
    "\n",
    "# Save the merged annotations to a new JSON file\n",
    "merged_data = {\n",
    "    'images': merged_images,\n",
    "    'annotations': merged_annotations,\n",
    "    'categories': merged_categories\n",
    "}\n",
    "\n",
    "with open(output_annotations_file, 'w') as f:\n",
    "    json.dump(merged_data, f)\n",
    "\n",
    "print(f'Combined dataset created with {len(merged_images)} images and {len(merged_annotations)} annotations.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
